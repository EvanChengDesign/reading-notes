**Reading Notes | 26 June 2024**

# Class 042

## **Questions & Answers**  

### Article 1: Google Backtracks, Says Its AI Will Not Be Used for Weapons or Surveillance

Google's decision to not use artificial intelligence for weapons or surveillance reflects a significant ethical stance in the technology industry. This move came after significant employee protests against the company's involvement in Project Maven, a Pentagon pilot program. The announcement, guided by AI principles set by CEO Sundar Pichai, aims to focus on creating "socially beneficial" AI and avoiding projects that cause "overall harm." This decision underscores the ethical responsibility tech companies bear when their innovations can potentially be used for harm. I agree with Google's stance as it highlights the importance of ethics in AI development, ensuring technology serves humanity positively. The employees' influence on corporate ethics stood out, showcasing the power of collective action in steering a company towards more responsible practices.

### Article 2: The Ethical Dilemmas of Self-Driving Cars

The ethical challenges of self-driving cars, particularly in unavoidable accident scenarios, present complex dilemmas about whom the vehicle should protect. Studies indicate that while autonomous cars could significantly reduce accidents, the decisions they must make in critical moments are ethically loaded. The debate includes considerations such as whether the car should prioritize the safety of passengers, pedestrians, or other road users. I find the discussion around programming AI to make ethical decisions fascinating and agree that these issues must be addressed before widespread adoption. What stood out was the double standard in how we judge human drivers versus machines, and the need for a collective effort from governments, manufacturers, and society to resolve these ethical questions. This highlights the broader societal implications of integrating advanced technology into everyday life.
